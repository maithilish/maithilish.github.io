<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Advanced on Codetab</title>
    <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/</link>
    <description>Recent content in Advanced on Codetab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jan 2019 23:03:00 +0530</lastBuildDate>
    
	<atom:link href="http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multi Dimensions - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/multi-dimensions/</link>
      <pubDate>Sat, 12 Jan 2019 06:14:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/multi-dimensions/</guid>
      <description>Multiple Dimensions In this chapter, we use an example of a Book Store listing page to explain multiple dimensions.
The defs/examples/book/page/page-1.html page lists details of 20 books similar to an e-commerce site. The Example 1 extracts one book and its related data.
The snippet of HTML of a book item is
&amp;lt;article class=&amp;#34;product_pod&amp;#34;&amp;gt; &amp;lt;div class=&amp;#34;image_container&amp;#34;&amp;gt; &amp;lt;a href=&amp;#34;catalogue/a-light-in-the-attic_1000/index.html&amp;#34;&amp;gt;&amp;lt;img src=&amp;#34;media/cache/cc35693c.jpg&amp;#34; alt=&amp;#34;A Light in the Attic&amp;#34; class=&amp;#34;thumbnail&amp;#34;&amp;gt;&amp;lt;/a&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;p class=&amp;#34;star-rating Three&amp;#34;&amp;gt; &amp;lt;i class=&amp;#34;icon-star&amp;#34;&amp;gt;&amp;lt;/i&amp;gt; &amp;lt;i class=&amp;#34;icon-star&amp;#34;&amp;gt;&amp;lt;/i&amp;gt; &amp;lt;i class=&amp;#34;icon-star&amp;#34;&amp;gt;&amp;lt;/i&amp;gt; &amp;lt;/p&amp;gt; &amp;lt;h3&amp;gt;&amp;lt;a href=&amp;#34;catalogue/a-light-in-the-attic_1000/index.</description>
    </item>
    
    <item>
      <title>Multi Tasks - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/multi-tasks/</link>
      <pubDate>Fri, 11 Jan 2019 23:51:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/multi-tasks/</guid>
      <description>Multiple Tasks Scoopi can execute multiple tasks for a locator and also multiple tasks on multiple locatorGroups.
Multiple tasks and single Locator group The Example-1 from fin folder scrape Price data from acme-snapshot.html page while Example-2 extracts Snapshot data from the same page. One option is to define acme-snapshot.html locator in two locatorGroups and assign task to each of them. This unnecessarily downloads acme-snapshot.html twice. Instead, it is better to define single locatorGroup and assign two tasks - priceTask and snapshotTask so that page downloads only once.</description>
    </item>
    
    <item>
      <title>Workflows Steps - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/workflow-steps-plugins/</link>
      <pubDate>Fri, 11 Jan 2019 23:59:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/workflow-steps-plugins/</guid>
      <description>Steps So far, we explored locators, tasks and dataDef to scrape data from the pages. But, we haven&amp;rsquo;t explained how Scoopi executes tasks and scrape data.
Scoopi is designed to execute tasks as workflow which is normally referred as steps which in turn consists of multiple step. Scoopi ships with two in-built defaults steps jsoupDefault and htmlUnitDefault and they are defined in steps-default.yml which is packaged inside Scoopi distribution jar.</description>
    </item>
    
    <item>
      <title>Converters - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/converters/</link>
      <pubDate>Sat, 12 Jan 2019 00:16:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/converters/</guid>
      <description>Converters This chapter explain adding new steps to workflow and converter plugins.
Add new Step We can add new steps at task level. The Example 8 adds converter step to jsoupDefault steps in bs task. The relevant snippet is shown below
defs/examples/fin/jsoup/ex-8/job.yml
bsTask: dataDef: bs steps: jsoupDefault: converter: class: &amp;#34;org.codetab.scoopi.step.process.DataConverter&amp;#34; previous: filter next: appender ....  The bsTask uses jsoupDefault built-in step as base and inserts converter step between filter and appender steps.</description>
    </item>
    
    <item>
      <title>Scripter - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/scripter/</link>
      <pubDate>Sat, 12 Jan 2019 06:29:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/scripter/</guid>
      <description>Script Plugin The example in the previous chapter converts date field using built-in DateRoller plugin. However, it is not possible to handle all types of modification with built-in plugins. To cope with myriad possibilities, Scoopi provides Scripter step to which user can hook arbitrary JavaScript to modify data.
Scripter Step The Example 8a adds process step to jsoupDefault steps in bs task. The relevant snippet is shown below
defs/examples/fin/jsoup/ex-8a/job.yml</description>
    </item>
    
    <item>
      <title>Scrape Links - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/create-locators-links/</link>
      <pubDate>Sat, 12 Jan 2019 00:29:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/create-locators-links/</guid>
      <description>Create Locators from Links The definitions would become lengthy when we define each and every link in job.xml. Instead, Scoopi can scrape links from any page and dynamically create locators. This feature allows you to recursively scrape the web pages. Let&amp;rsquo;s see how to create locators from scraped links.
Link Scrape Step The Example 9 scrapes Balance Sheet and Profit &amp;amp; Loss links from acme-snapshot.html page. Links snippet in the html page is as below.</description>
    </item>
    
    <item>
      <title>Pagination - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/pagination/</link>
      <pubDate>Sat, 12 Jan 2019 06:40:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/pagination/</guid>
      <description>Pagination Many pages provide pagination buttons or links to navigate through series of pages. We can use link locators described in previous chapter to scrape pages using pagination.
The Books example folder contains three HTML pages which has pagination link at the bottom of pages.
defs/examples/book/page/page-1.html
&amp;lt;div&amp;gt; &amp;lt;ul class=&amp;#34;pager&amp;#34;&amp;gt; &amp;lt;li class=&amp;#34;current&amp;#34;&amp;gt;Page 1 of 50&amp;lt;/li&amp;gt; &amp;lt;li class=&amp;#34;next&amp;#34;&amp;gt;&amp;lt;a href=&amp;#34;page-2.html&amp;#34;&amp;gt;next&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; The Books Example 4 go through each page and scrape book items.</description>
    </item>
    
    <item>
      <title>Appenders Encoders - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/appender-encoder/</link>
      <pubDate>Sat, 12 Jan 2019 01:09:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/appender-encoder/</guid>
      <description>Appender and Encoder Scoopi uses appender to append data to output and encoder to encode or alter the output format. At present, it comes with two appender - FileAppender and ListAppender.
FileAppender So far, examples use FileAppender of default steps defined in steps-default.yml which is packaged with scoopi distribution jar. The appender snippet is as below.
appender: class: &amp;#34;org.codetab.scoopi.step.load.DataAppender&amp;#34; previous: filter next: end plugins: [ plugin: { name: dataFile, class: &amp;#34;org.</description>
    </item>
    
    <item>
      <title>DOM Loader - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/dom-loader-selenium-webdriver/</link>
      <pubDate>Sat, 12 Jan 2019 06:47:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/dom-loader-selenium-webdriver/</guid>
      <description>JavaScript and WebDriver So far in the guide, the examples scrape data from regular HTML pages. But, we encounter many web pages that generates and renders pages with JavaScript or Ajax functions. In this and next chapter, we explore ways to seamlessly scrape such pages.
Dynamically generated pages The website toscrape.com has many endpoints showing the quotes in many different way that are generated through DOM manipulation.
Open JavaScript - JavaScript generated contents page and view its page source.</description>
    </item>
    
    <item>
      <title>Ajax - Scoopi Web Scraper - why just scrape when you can scoop</title>
      <link>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/ajax-selenium-webdriver/</link>
      <pubDate>Sat, 12 Jan 2019 07:03:00 +0530</pubDate>
      
      <guid>http://www.codetab.org/tutorial/scoopi-web-scraper/advanced/ajax-selenium-webdriver/</guid>
      <description>Browser interaction with WebDriver In this previous chapter, we scrape data from page with JavaScript created contents. In this chapter, we extend it further and show how to interact with WebDriver to emulate browser automation.
Browser Scrolling and Ajax The Quote Example 2 scrape quotations from Scroll - infinite scrolling pagination page loads next set of quotes through Ajax call when we scroll to the bottom of browser.
The locator and task snippet from this example is as below.</description>
    </item>
    
  </channel>
</rss>